{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"./\")\n",
    "# + \"/drive/MyDrive/Colab Notebooks/deep-hedging-master\"\n",
    "# from IPython.display import clear_output\n",
    "print(\"   \", os.getcwd())\n",
    "import numpy as np\n",
    "import QuantLib as ql\n",
    "import tensorflow as tf\n",
    "from scipy.stats import norm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.compat.v1.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from stochastic_processes import BlackScholesProcess\n",
    "from instruments import EuropeanCall\n",
    "from loss_metrics import Entropy\n",
    "from utilities import train_test_split\n",
    "\n",
    "# tf.config.experimental_run_functions_eagerly(True)\n",
    "# tf.config.set_soft_device_placement(True)\n",
    "tf.config.experimental.list_physical_devices(device_type=\"GPU\")\n",
    "print(\"\\nFinish installing and importing all necessary libraries!\", tf.__version__)\n",
    "print(\"\\ntf.test.is_gpu_available:\", tf.test.is_gpu_available())\n",
    "\n",
    "from deep_hedging.deep_hedging_gru import Deep_Hedging_Model, Delta_SubModel\n",
    "\n",
    "\n",
    "device_id = 0\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "gpu = gpus[device_id]\n",
    "tf.config.set_visible_devices(gpu, 'GPU')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# <font color='Blue'>**User Inputs**</font>\n",
    "print(\"=====\") \n",
    "# Geometric Brownian Motion.\n",
    "N = 30  # Number of time steps (in days)\n",
    "\n",
    "S0 = 100  # Stock price at time = 0\n",
    "sigma = 0.1224# Implied volatility\n",
    "risk_free = 0.0  # Risk-free rate\n",
    "dividend = 0.0  # Continuous dividend yield\n",
    "print(\"=====\")\n",
    "Ktrain = 1 * (10 ** 5)  # Size of training sample.\n",
    "Ktest_ratio = 0.2  # Fraction of training sample as testing sample.\n",
    "\n",
    "# European call option (short).\n",
    "strike = S0\n",
    "payoff_func = lambda x: -np.maximum(x - strike, 0.0)\n",
    "calculation_date = ql.Date.todaysDate()\n",
    "maturity_date = ql.Date.todaysDate() + N\n",
    "\n",
    "# Day convention.\n",
    "day_count = ql.Actual365Fixed()  # Actual/Actual (ISDA)\n",
    "\n",
    "# Proportional transaction cost.\n",
    "epsilon = 0.0\n",
    "\n",
    "# Information set (in string)\n",
    "# Choose from: S, log_S, normalized_log_S (by S0)\n",
    "information_set = \"normalized_log_S\"\n",
    "\n",
    "# Loss function\n",
    "# loss_type = \"CVaR\" (Expected Shortfall) -> loss_param = alpha\n",
    "# loss_type = \"Entropy\" -> loss_param = lambda\n",
    "\n",
    "loss_type = \"Entropy\"\n",
    "loss_param = 1.0\n",
    "\n",
    "# Neural network (NN) structure\n",
    "m = 15  # Number of neurons in each hidden layer.\n",
    "d = 1  # Number of hidden layers (Note including input nor output layer)\n",
    "\n",
    "# Neural network training parameters\n",
    "lr = 1e-2  # Learning rate\n",
    "batch_size = 400  # Batch size\n",
    "epochs = 50 # Number of epochs\n",
    "\n",
    "# Other parameters\n",
    "use_batch_norm = False\n",
    "kernel_initializer = \"he_uniform\"\n",
    "\n",
    "activation_dense = \"leaky_relu\"\n",
    "activation_output = \"sigmoid\"\n",
    "final_period_cost = False\n",
    "\n",
    "delta_constraint = (0.0, 1.0)\n",
    "share_stretegy_across_time = False\n",
    "cost_structure = \"proportional\"\n",
    "\n",
    "# Other control flags for development purpose.\n",
    "mc_simulator = \"QuantLib\"  # \"QuantLib\" or \"Numpy\"\n",
    "\n",
    "seed = 0  # Random seed. Change to have deterministic outcome.\n",
    "\n",
    "print(\"---------\")\n",
    "\n",
    "# Total obs = Training + Testing\n",
    "nobs = int(Ktrain * (1 + Ktest_ratio))\n",
    "\n",
    "# Length of one time-step (as fraction of a year).\n",
    "dt = day_count.yearFraction(calculation_date, calculation_date + 1)\n",
    "maturity = N * dt  # Maturities (in the unit of a year)\n",
    "\n",
    "# Total obs = Training + Testing\n",
    "S = np.load('./data/deep_hedging/rb_price.npy')\n",
    "list_true = []\n",
    "for i in S[:,-1]:\n",
    "    if i>70 and i<130:\n",
    "        list_true.append(True)\n",
    "    else:\n",
    "        list_true.append(False)\n",
    "aa = S[list_true]\n",
    "S = aa[0:(aa.shape[0]//400)*400,:]\n",
    "# S = 100*S\n",
    "# S = S\n",
    "stochastic_process = BlackScholesProcess(s0 = S0, sigma = sigma, risk_free = risk_free, \\\n",
    "                        dividend = dividend, day_count = day_count, seed=seed)\n",
    "\n",
    "# S = stochastic_process.gen_path(maturity, N, nobs)\n",
    "# <font color='Blue'>**Prepare data to be fed into the deep hedging algorithm.**</font>\n",
    "\n",
    "payoff_T = payoff_func(S[:, -1])  # Payoff of the call option\n",
    "\n",
    "trade_set = np.stack((S), axis=1)  # Trading set\n",
    "\n",
    "if information_set is \"S\":\n",
    "    I = np.stack((S), axis=1)  # Information set\n",
    "elif information_set is \"log_S\":\n",
    "    I = np.stack((np.log(S)), axis=1)\n",
    "elif information_set is \"normalized_log_S\":\n",
    "    I = np.stack((np.log(S / S0)), axis=1)\n",
    "\n",
    "# Structure of xtrain:\n",
    "#   1) Trade set: [S]\n",
    "#   2) Information set: [S]\n",
    "#   3) payoff (dim = 1)\n",
    "x_all = []\n",
    "for i in range(N + 1):\n",
    "    x_all += [trade_set[i, :, None]]\n",
    "    if i != N:\n",
    "        x_all += [I[i, :, None]]\n",
    "x_all += [payoff_T[:, None]]\n",
    "\n",
    "# Split the entire sample into a training sample and a testing sample.\n",
    "test_size = int(Ktrain * Ktest_ratio)\n",
    "[xtrain, xtest] = train_test_split(x_all, test_size=test_size)  # 62*100000, 62*20000\n",
    "[S_train, S_test] = train_test_split([S], test_size=test_size)  # 100000*31， 20000*31\n",
    "[option_payoff_train, option_payoff_test] = train_test_split([x_all[-1]], test_size=test_size)  # 1*100000， 1*20000\n",
    "\n",
    "print(\"Finish preparing data!\")\n",
    "\n",
    "\n",
    "\n",
    "optimizer = Adam(learning_rate=lr,amsgrad=True)\n",
    "\n",
    "# Setup and compile the model\n",
    "model_recurrent = Deep_Hedging_Model(N=N, d=d + 2, m=m, risk_free=risk_free, \\\n",
    "                                    dt=dt, strategy_type=\"recurrent\", epsilon=epsilon, \\\n",
    "                                    use_batch_norm=use_batch_norm, kernel_initializer=kernel_initializer, \\\n",
    "                                    activation_dense=activation_dense, activation_output=activation_output, \\\n",
    "                                    final_period_cost=final_period_cost,share_stretegy_across_time=True)\n",
    "\n",
    "loss = Entropy(model_recurrent.output, None, loss_param)\n",
    "model_recurrent.add_loss(loss)\n",
    "\n",
    "model_recurrent.compile(optimizer=optimizer)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"loss\", \\\n",
    "                            patience=10, min_delta=1e-4, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"loss\", \\\n",
    "                            factor=0.5, patience=2, min_delta=1e-3, verbose=0)\n",
    "\n",
    "callbacks = [early_stopping, reduce_lr]\n",
    "dataset = []\n",
    "print(\"============\", len(xtrain))\n",
    "# for i in range(len(xtrain)):\n",
    "#     print(\"--i is \",i)\n",
    "#     dataset = dataset + [tf.data.Dataset.from_tensor_slices(xtrain).batch(batch_size=batch_size)]\n",
    "# dataset = tf.data.Dataset.from_tensor_slices(xtrain)\n",
    "# dataset = dataset.batch(batch_size=batch_size)\n",
    "# Fit the model.\n",
    "model_recurrent.fit(x=xtrain, batch_size=batch_size, epochs=epochs, validation_data=xtest, verbose=1)  #\n",
    "# model_recurrent.fit(x=dataset,  epochs=epochs,  verbose=1)  #\n",
    "\n",
    "# clear_output()\n",
    "print(\"Finished running deep hedging algorithm! (Simple Network)\")\n",
    "\n",
    "print(\"\\n\\ns0 = \" + str(S0))\n",
    "print(\"sigma = \" + str(sigma))\n",
    "print(\"risk_free = \" + str(risk_free) + \"\\n\")\n",
    "print(\"Number of time steps = \" + str(N))\n",
    "print(\"Length of each time step = \" + \"1/365\\n\")\n",
    "print(\"Simulation Done!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_recurrent.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call = EuropeanCall()\n",
    "\n",
    "price_BS = call.get_BS_price(S = S_test[0], sigma = sigma, \\\n",
    "              risk_free = risk_free, dividend = dividend, K = strike, \\\n",
    "              exercise_date = maturity_date, \\\n",
    "              calculation_date = calculation_date, \\\n",
    "              day_count = day_count, dt = dt)\n",
    "delta_BS = call.get_BS_delta(S = S_test[0], sigma = sigma, \\\n",
    "              risk_free = risk_free, dividend = dividend, K = strike, \\\n",
    "              exercise_date = maturity_date, \\\n",
    "              calculation_date = calculation_date, \n",
    "              day_count = day_count, dt = dt)\n",
    "\n",
    "PnL_BS =  call.get_BS_PnL(S= S_test[0], \\\n",
    "              payoff= payoff_func(S_test[0][:,-1]), delta=delta_BS, \\\n",
    "              dt= dt, risk_free = risk_free, \\\n",
    "              final_period_cost=final_period_cost, epsilon=epsilon, \\\n",
    "              cost_structure = cost_structure )\n",
    "\n",
    "risk_neutral_price = \\\n",
    "    -option_payoff_test[0].mean()*np.exp(-risk_free*(N*dt))\n",
    "risk_neutral_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"The Black-Scholes model price is %2.3f.\" % price_BS[0][0])\n",
    "print(\"The Risk Neutral price is %2.3f.\" % risk_neutral_price)\n",
    "\n",
    "nn_recurrent_price = model_recurrent.evaluate(xtest, batch_size=batch_size, verbose=0)\n",
    "try:\n",
    "  print(\"aaaa\")\n",
    "  nn_recurrent_price = model_recurrent.evaluate(xtest, batch_size=batch_size, verbose=0)\n",
    "  print(\"The Deep Hedging (with recurrent network) price is %2.3f.\" % nn_recurrent_price)\n",
    "except:\n",
    "  print(\"No Recurrent model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "bar1 = PnL_BS + price_BS[0][0]\n",
    "bar2 = model_recurrent.predict(xtest,batch_size=batch_size).squeeze() + price_BS[0][0]\n",
    "\n",
    "# Plot Black-Scholes PnL and Deep Hedging PnL (with BS_price charged on both).\n",
    "fig_PnL = plt.figure(dpi= 125, facecolor='w')\n",
    "fig_PnL.suptitle(\"Black-Scholes PnL vs Rb Deep Hedging PnL \\n\", \\\n",
    "      fontweight=\"bold\")\n",
    "ax = fig_PnL.add_subplot()\n",
    "# ax.set_title(\"Simple Network Structure with epsilon = \" + str(epsilon), \\\n",
    "#       fontsize=8)\n",
    "ax.set_xlabel(\"PnL\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "# ax.set_xbound(lower=-0.5,upper=0.5)\n",
    "ax.set_xlim(-10,5)\n",
    "ax.hist((bar1,bar2), bins=120, \\\n",
    "          label=[\"Black-Scholes PnL\",\"Heston Deep Hedging PnL\"])\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar1_rb_ftse = np.loadtxt('bar1_heston_spx.npz')\n",
    "bar2_rb_ftse = np.loadtxt('bar2_heston_spx.npz')\n",
    "\n",
    "\n",
    "# Plot Black-Scholes PnL and Deep Hedging PnL (with BS_price charged on both).\n",
    "fig_PnL = plt.figure(dpi= 125, facecolor='w')\n",
    "fig_PnL.suptitle(\"Heston deep hedging P&L vs rBergomi deep hedging P&L \\n\", \\\n",
    "      fontweight=\"bold\")\n",
    "ax = fig_PnL.add_subplot()\n",
    "# ax.set_title(\"Simple Network Structure with epsilon = \" + str(epsilon), \\\n",
    "#       fontsize=8)\n",
    "ax.set_xlabel(\"P&L\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "ax.set_xbound(lower=-0.5,upper=0.5)\n",
    "# ax.set_xlim(-2,1.5)\n",
    "ax.hist((bar1_rb_ftse+0.6,bar2_rb_ftse+0.6,bar2), bins=90, \\\n",
    "          label=[\"Black-Scholes P&L\",\"Heston deep hedging P&L\",\"RBergomi deep hedging P&L\"],\n",
    "          color=['#C03302','#B88572','#3A001E'])\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = bar2\n",
    "print(\"rBergomi-ftse-mean\",np.mean(aa))\n",
    "print(\"rBergomi-ftse-std\",np.std(aa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"heston-ftse-mean\",np.mean(bar2_rb_ftse))\n",
    "print(\"heston-ftse-std\",np.std(bar2_rb_ftse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# def var_historic(r, level=1):\n",
    "#     \"\"\"\n",
    "#     Takes in a series of returns (r), and the percentage level\n",
    "# (level)\n",
    "#     Returns the historic Value at Risk at a specified level\n",
    "#     i.e. returns the number such that \"level\" percent of the returns\n",
    "#     fall below that number, and the (100-level) percent are above\n",
    "#     \"\"\"\n",
    "#     if isinstance(r, pd.DataFrame):\n",
    "#         return r.aggregate(var_historic, level=level)\n",
    "#     elif isinstance(r, pd.Series):\n",
    "#         return -np.percentile(r, level)\n",
    "#     else:\n",
    "#         raise TypeError(\"Expected r to be a Series or DataFrame\")\n",
    "# varheston99=var_historic(pd.Series(bar2_rb_ftse), level=0.99)\n",
    "# varheston90=var_historic(pd.Series(bar2_rb_ftse), level=0.90)\n",
    "# varheston60=var_historic(pd.Series(bar2_rb_ftse), level=0.60)\n",
    "# print(\"varheston99:\",varheston99)\n",
    "# print(\"varheston90:\",varheston90)\n",
    "# print(\"varheston60:\",varheston60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def var_historic(r, level=1):\n",
    "    \"\"\"\n",
    "    Takes in a series of returns (r), and the percentage level\n",
    "(level)\n",
    "    Returns the historic Value at Risk at a specified level\n",
    "    i.e. returns the number such that \"level\" percent of the returns\n",
    "    fall below that number, and the (100-level) percent are above\n",
    "    \"\"\"\n",
    "    if isinstance(r, pd.DataFrame):\n",
    "        return r.aggregate(var_historic, level=level)\n",
    "    elif isinstance(r, pd.Series):\n",
    "        return -np.percentile(r, level)\n",
    "    else:\n",
    "        raise TypeError(\"Expected r to be a Series or DataFrame\")\n",
    "varheston99=var_historic(pd.Series(aa), level=0.99)\n",
    "varheston90=var_historic(pd.Series(aa), level=0.90)\n",
    "varheston60=var_historic(pd.Series(aa), level=0.60)\n",
    "print(\"varrB99:\",varheston99)\n",
    "print(\"varrB90:\",varheston90)\n",
    "print(\"varrB60:\",varheston60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def var_historic(r, level=1):\n",
    "    \"\"\"\n",
    "    Takes in a series of returns (r), and the percentage level\n",
    "(level)\n",
    "    Returns the historic Value at Risk at a specified level\n",
    "    i.e. returns the number such that \"level\" percent of the returns\n",
    "    fall below that number, and the (100-level) percent are above\n",
    "    \"\"\"\n",
    "    if isinstance(r, pd.DataFrame):\n",
    "        return r.aggregate(var_historic, level=level)\n",
    "    elif isinstance(r, pd.Series):\n",
    "        return -np.percentile(r, level)\n",
    "    else:\n",
    "        raise TypeError(\"Expected r to be a Series or DataFrame\")\n",
    "varheston99=var_historic(pd.Series(bar1_rb_ftse), level=0.99)\n",
    "varheston90=var_historic(pd.Series(bar1_rb_ftse), level=0.90)\n",
    "varheston60=var_historic(pd.Series(bar1_rb_ftse), level=0.60)\n",
    "print(\"varBS99:\",varheston99)\n",
    "print(\"varBS90:\",varheston90)\n",
    "print(\"varBS60:\",varheston60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15 (default, Nov 24 2022, 18:44:54) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0b9be10dbf2f757c6dd8c30fd0ea7dd38ee9e768dd20fb7638a80f027924761c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
